# Mentor TypeScript - Agente Fullstack

Este projeto Ã© um assistente de IA especializado em desenvolvimento TypeScript Fullstack, construÃ­do com [Next.js](https://nextjs.org) e integrado ao [Ollama](https://ollama.ai) para processamento local de linguagem natural.

## ğŸš€ Funcionalidades

- **Chat Interativo**: Interface amigÃ¡vel para conversar com o agente.
- **Respostas em Streaming**: VisualizaÃ§Ã£o das respostas token por token em tempo real.
- **Especialista em TS**: O agente Ã© configurado para auxiliar em TypeScript, Node.js, React, testes e arquitetura.
- **SugestÃµes RÃ¡pidas**: Exemplos de prompts prontos para testar as capacidades do agente.
- **Design Moderno**: Interface limpa e responsiva estilizada com TailwindCSS.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Frontend**: [Next.js 16](https://nextjs.org) (App Router), React 19.
- **EstilizaÃ§Ã£o**: [TailwindCSS v4](https://tailwindcss.com).
- **IA / LLM**: [Ollama](https://ollama.ai) (Local LLM Server).
- **Linguagem**: TypeScript.

## ğŸ“‹ PrÃ©-requisitos

Antes de rodar o projeto, vocÃª precisa configurar o ambiente:

1.  **Node.js**: Certifique-se de ter o Node.js instalado (versÃ£o 20 ou superior recomendada).
2.  **Ollama**: Instale o [Ollama](https://ollama.ai/download) em sua mÃ¡quina.
3.  **Modelo LLM**: O projeto estÃ¡ configurado para usar o modelo `deepseek-coder:6.7b`. VocÃª precisa baixÃ¡-lo via Ollama:

    ```bash
    ollama pull deepseek-coder:6.7b
    ```

    > **Nota**: Se desejar usar outro modelo, altere a string `"model"` no arquivo `services/ollama.ts`.

## ğŸ“¦ InstalaÃ§Ã£o e Uso

1.  Clone o repositÃ³rio e entre na pasta:
    ```bash
    cd agent-ts
    ```

2.  Instale as dependÃªncias:
    ```bash
    npm install
    # ou
    yarn install
    # ou
    pnpm install
    ```

3.  Inicie o servidor de desenvolvimento:
    ```bash
    npm run dev
    ```

4.  Abra [http://localhost:3000](http://localhost:3000) no seu navegador.

## ğŸ”§ Estrutura do Projeto

- `app/page.tsx`: Interface principal do chat.
- `app/api/prompt/route.ts`: API Route que proxia as requisiÃ§Ãµes para o Ollama.
- `services/ollama.ts`: LÃ³gica de comunicaÃ§Ã£o com o servidor Ollama local (porta 11434).
- `lib/validators.ts`: (Se houver) ValidaÃ§Ãµes e utilitÃ¡rios.

## ğŸ¤ ContribuiÃ§Ã£o

Sinta-se Ã  vontade para abrir issues ou enviar PRs para melhorar este agente!
